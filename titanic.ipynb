{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>714.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "      <td>891.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.383838</td>\n",
       "      <td>2.308642</td>\n",
       "      <td>29.699118</td>\n",
       "      <td>0.523008</td>\n",
       "      <td>0.381594</td>\n",
       "      <td>32.204208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>257.353842</td>\n",
       "      <td>0.486592</td>\n",
       "      <td>0.836071</td>\n",
       "      <td>14.526497</td>\n",
       "      <td>1.102743</td>\n",
       "      <td>0.806057</td>\n",
       "      <td>49.693429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>223.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>20.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>7.910400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>446.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.454200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>668.500000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>891.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>512.329200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
       "count   891.000000  891.000000  891.000000  714.000000  891.000000   \n",
       "mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
       "std     257.353842    0.486592    0.836071   14.526497    1.102743   \n",
       "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
       "25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n",
       "50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n",
       "75%     668.500000    1.000000    3.000000   38.000000    1.000000   \n",
       "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
       "\n",
       "            Parch        Fare  \n",
       "count  891.000000  891.000000  \n",
       "mean     0.381594   32.204208  \n",
       "std      0.806057   49.693429  \n",
       "min      0.000000    0.000000  \n",
       "25%      0.000000    7.910400  \n",
       "50%      0.000000   14.454200  \n",
       "75%      0.000000   31.000000  \n",
       "max      6.000000  512.329200  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "titanic_file = 'train.csv'\n",
    "test_file = 'test.csv'\n",
    "data = pd.read_csv(titanic_file)\n",
    "test_data = pd.read_csv(test_file)\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 8 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   Survived  891 non-null    int64  \n",
      " 1   Pclass    891 non-null    int64  \n",
      " 2   Sex       891 non-null    int64  \n",
      " 3   Age       891 non-null    float64\n",
      " 4   SibSp     891 non-null    int64  \n",
      " 5   Parch     891 non-null    int64  \n",
      " 6   Fare      891 non-null    float64\n",
      " 7   Embarked  891 non-null    int64  \n",
      "dtypes: float64(2), int64(6)\n",
      "memory usage: 55.8 KB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\OMEN\\AppData\\Local\\Temp\\ipykernel_28652\\854726192.py:11: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  data['Embarked'].fillna(data['Embarked'].mode()[0], inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None,\n",
       "    Survived  Pclass  Sex   Age  SibSp  Parch     Fare  Embarked\n",
       " 0         0       3    0  22.0      1      0   7.2500         2\n",
       " 1         1       1    1  38.0      1      0  71.2833         0\n",
       " 2         1       3    1  26.0      0      0   7.9250         2\n",
       " 3         1       1    1  35.0      1      0  53.1000         2\n",
       " 4         0       3    0  35.0      0      0   8.0500         2)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 1: Handle missing values\n",
    "\n",
    "# Fill missing Age with median grouped by Pclass and Sex\n",
    "\n",
    "data['Age'] = data.groupby(['Pclass', 'Sex'])['Age'].transform(lambda x: x.fillna(x.median()))\n",
    "\n",
    "\n",
    "\n",
    "# Fill missing Embarked with the mode\n",
    "\n",
    "data['Embarked'].fillna(data['Embarked'].mode()[0], inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "# Drop the Cabin column due to high missingness\n",
    "\n",
    "data.drop('Cabin', axis=1, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "# Step 2: Convert categorical variables\n",
    "\n",
    "# Encode 'Sex' and 'Embarked'\n",
    "\n",
    "data['Sex'] = data['Sex'].map({'male': 0, 'female': 1})\n",
    "\n",
    "data['Embarked'] = data['Embarked'].map({'C': 0, 'Q': 1, 'S': 2})\n",
    "\n",
    "\n",
    "\n",
    "# Step 3: Drop unnecessary columns\n",
    "\n",
    "data_cleaned = data.drop(['Name', 'Ticket', 'PassengerId'], axis=1)\n",
    "\n",
    "\n",
    "\n",
    "# Check the cleaned data\n",
    "\n",
    "data_cleaned.info(), data_cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 418 entries, 0 to 417\n",
      "Data columns (total 7 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   Pclass    418 non-null    int64  \n",
      " 1   Sex       418 non-null    int64  \n",
      " 2   Age       418 non-null    float64\n",
      " 3   SibSp     418 non-null    int64  \n",
      " 4   Parch     418 non-null    int64  \n",
      " 5   Fare      418 non-null    float64\n",
      " 6   Embarked  418 non-null    int64  \n",
      "dtypes: float64(2), int64(5)\n",
      "memory usage: 23.0 KB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\OMEN\\AppData\\Local\\Temp\\ipykernel_28652\\869952163.py:11: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  test_data['Embarked'].fillna(test_data['Embarked'].mode()[0], inplace=True)\n",
      "C:\\Users\\OMEN\\AppData\\Local\\Temp\\ipykernel_28652\\869952163.py:15: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  test_data['Fare'].fillna(test_data['Fare'].mode()[0], inplace=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None,\n",
       "    Pclass  Sex   Age  SibSp  Parch     Fare  Embarked\n",
       " 0       3    0  34.5      0      0   7.8292         1\n",
       " 1       3    1  47.0      1      0   7.0000         2\n",
       " 2       2    0  62.0      0      0   9.6875         1\n",
       " 3       3    0  27.0      0      0   8.6625         2\n",
       " 4       3    1  22.0      1      1  12.2875         2)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 1: Handle missing values\n",
    "\n",
    "# Fill missing Age with median grouped by Pclass and Sex\n",
    "\n",
    "test_data['Age'] = test_data.groupby(['Pclass', 'Sex'])['Age'].transform(lambda x: x.fillna(x.median()))\n",
    "\n",
    "\n",
    "\n",
    "# Fill missing Embarked with the mode\n",
    "\n",
    "test_data['Embarked'].fillna(test_data['Embarked'].mode()[0], inplace=True)\n",
    "\n",
    "# Fill missing Fare with the mode\n",
    "\n",
    "test_data['Fare'].fillna(test_data['Fare'].mode()[0], inplace=True)\n",
    "\n",
    "\n",
    "# Drop the Cabin column due to high missingness\n",
    "\n",
    "test_data.drop('Cabin', axis=1, inplace=True)\n",
    "\n",
    "\n",
    "\n",
    "# Step 2: Convert categorical variables\n",
    "\n",
    "# Encode 'Sex' and 'Embarked'\n",
    "\n",
    "test_data['Sex'] = test_data['Sex'].map({'male': 0, 'female': 1})\n",
    "\n",
    "test_data['Embarked'] = test_data['Embarked'].map({'C': 0, 'Q': 1, 'S': 2})\n",
    "\n",
    "\n",
    "\n",
    "# Step 3: Drop unnecessary columns\n",
    "\n",
    "test_data_cleaned = test_data.drop(['Name', 'Ticket', 'PassengerId'], axis=1)\n",
    "\n",
    "\n",
    "\n",
    "# Check the cleaned data\n",
    "\n",
    "test_data_cleaned.info(), test_data_cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 9 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   Survived      891 non-null    int64  \n",
      " 1   Pclass        891 non-null    int64  \n",
      " 2   Sex           891 non-null    int64  \n",
      " 3   Age           891 non-null    float64\n",
      " 4   Fare          891 non-null    float64\n",
      " 5   Embarked      891 non-null    int64  \n",
      " 6   FamilySize    891 non-null    int64  \n",
      " 7   AgeGroup      891 non-null    int8   \n",
      " 8   FareCategory  891 non-null    int8   \n",
      "dtypes: float64(2), int64(5), int8(2)\n",
      "memory usage: 50.6 KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None,\n",
       "    Survived  Pclass  Sex   Age     Fare  Embarked  FamilySize  AgeGroup  \\\n",
       " 0         0       3    0  22.0   7.2500         2           2         2   \n",
       " 1         1       1    1  38.0  71.2833         0           2         3   \n",
       " 2         1       3    1  26.0   7.9250         2           1         2   \n",
       " 3         1       1    1  35.0  53.1000         2           2         2   \n",
       " 4         0       3    0  35.0   8.0500         2           1         2   \n",
       " \n",
       "    FareCategory  \n",
       " 0             0  \n",
       " 1             3  \n",
       " 2             1  \n",
       " 3             3  \n",
       " 4             1  )"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 1: Create FamilySize feature\n",
    "\n",
    "data_cleaned['FamilySize'] = data_cleaned['SibSp'] + data_cleaned['Parch'] + 1\n",
    "\n",
    "\n",
    "\n",
    "# Step 2: Bin Age into categories\n",
    "\n",
    "bins_age = [0, 12, 18, 35, 60, 100]  # Age groups: Child, Teen, Adult, Senior\n",
    "\n",
    "labels_age = ['Child', 'Teen', 'Adult', 'Middle_Aged', 'Senior']\n",
    "\n",
    "data_cleaned['AgeGroup'] = pd.cut(data_cleaned['Age'], bins=bins_age, labels=labels_age)\n",
    "\n",
    "\n",
    "\n",
    "# Encode AgeGroup numerically\n",
    "\n",
    "data_cleaned['AgeGroup'] = data_cleaned['AgeGroup'].cat.codes\n",
    "\n",
    "\n",
    "\n",
    "# Step 3: Bin Fare into categories\n",
    "\n",
    "bins_fare = [-1, 7.91, 14.454, 31.0, 512.3292]  # Fare categories based on dataset distribution\n",
    "\n",
    "labels_fare = ['Low', 'Mid-Low', 'Mid-High', 'High']\n",
    "\n",
    "data_cleaned['FareCategory'] = pd.cut(data_cleaned['Fare'], bins=bins_fare, labels=labels_fare)\n",
    "\n",
    "\n",
    "\n",
    "# Encode FareCategory numerically\n",
    "\n",
    "data_cleaned['FareCategory'] = data_cleaned['FareCategory'].cat.codes\n",
    "\n",
    "\n",
    "\n",
    "# Step 4: Drop SibSp and Parch as FamilySize replaces them\n",
    "\n",
    "data_final = data_cleaned.drop(['SibSp', 'Parch'], axis=1)\n",
    "\n",
    "\n",
    "\n",
    "# Check the final feature set\n",
    "\n",
    "data_final.info(), data_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 418 entries, 0 to 417\n",
      "Data columns (total 8 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   Pclass        418 non-null    int64  \n",
      " 1   Sex           418 non-null    int64  \n",
      " 2   Age           418 non-null    float64\n",
      " 3   Fare          418 non-null    float64\n",
      " 4   Embarked      418 non-null    int64  \n",
      " 5   FamilySize    418 non-null    int64  \n",
      " 6   AgeGroup      418 non-null    int8   \n",
      " 7   FareCategory  418 non-null    int8   \n",
      "dtypes: float64(2), int64(4), int8(2)\n",
      "memory usage: 20.5 KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(None,\n",
       "    Pclass  Sex   Age     Fare  Embarked  FamilySize  AgeGroup  FareCategory\n",
       " 0       3    0  34.5   7.8292         1           1         2             0\n",
       " 1       3    1  47.0   7.0000         2           2         3             0\n",
       " 2       2    0  62.0   9.6875         1           1         4             1\n",
       " 3       3    0  27.0   8.6625         2           1         2             1\n",
       " 4       3    1  22.0  12.2875         2           3         2             1)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 1: Create FamilySize feature\n",
    "\n",
    "test_data_cleaned['FamilySize'] = test_data_cleaned['SibSp'] + test_data_cleaned['Parch'] + 1\n",
    "\n",
    "\n",
    "\n",
    "# Step 2: Bin Age into categories\n",
    "\n",
    "bins_age = [0, 12, 18, 35, 60, 100]  # Age groups: Child, Teen, Adult, Senior\n",
    "\n",
    "labels_age = ['Child', 'Teen', 'Adult', 'Middle_Aged', 'Senior']\n",
    "\n",
    "test_data_cleaned['AgeGroup'] = pd.cut(test_data_cleaned['Age'], bins=bins_age, labels=labels_age)\n",
    "\n",
    "\n",
    "\n",
    "# Encode AgeGroup numerically\n",
    "\n",
    "test_data_cleaned['AgeGroup'] = test_data_cleaned['AgeGroup'].cat.codes\n",
    "\n",
    "\n",
    "\n",
    "# Step 3: Bin Fare into categories\n",
    "\n",
    "bins_fare = [-1, 7.91, 14.454, 31.0, 512.3292]  # Fare categories based on dataset distribution\n",
    "\n",
    "labels_fare = ['Low', 'Mid-Low', 'Mid-High', 'High']\n",
    "\n",
    "test_data_cleaned['FareCategory'] = pd.cut(test_data_cleaned['Fare'], bins=bins_fare, labels=labels_fare)\n",
    "\n",
    "\n",
    "\n",
    "# Encode FareCategory numerically\n",
    "\n",
    "test_data_cleaned['FareCategory'] = test_data_cleaned['FareCategory'].cat.codes\n",
    "\n",
    "\n",
    "\n",
    "# Step 4: Drop SibSp and Parch as FamilySize replaces them\n",
    "\n",
    "test_data_final = test_data_cleaned.drop(['SibSp', 'Parch'], axis=1)\n",
    "\n",
    "\n",
    "\n",
    "# Check the final feature set\n",
    "\n",
    "test_data_final.info(), test_data_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[ 0.82737724, -0.73769513, -0.53489116, -0.50244517,  0.58595414,\n",
       "          0.05915988, -0.06848951, -1.34677659],\n",
       "        [-1.56610693,  1.35557354,  0.66839176,  0.78684529, -1.9423032 ,\n",
       "          0.05915988,  1.10505182,  1.33773782],\n",
       "        [ 0.82737724,  1.35557354, -0.23407043, -0.48885426,  0.58595414,\n",
       "         -0.56097483, -0.06848951, -0.45193845],\n",
       "        [-1.56610693,  1.35557354,  0.44277621,  0.42073024,  0.58595414,\n",
       "          0.05915988, -0.06848951,  1.33773782],\n",
       "        [ 0.82737724, -0.73769513,  0.44277621, -0.48633742,  0.58595414,\n",
       "         -0.56097483, -0.06848951, -0.45193845]]),\n",
       " array([[ 0.82737724, -0.73769513,  0.40517362, -0.49078316, -0.67817453,\n",
       "         -0.56097483, -0.06848951, -1.34677659],\n",
       "        [ 0.82737724,  1.35557354,  1.3452384 , -0.50747884,  0.58595414,\n",
       "          0.05915988,  1.10505182, -1.34677659],\n",
       "        [-0.36936484, -0.73769513,  2.47331614, -0.45336687, -0.67817453,\n",
       "         -0.56097483,  2.27859315, -0.45193845],\n",
       "        [ 0.82737724, -0.73769513, -0.15886525, -0.47400493,  0.58595414,\n",
       "         -0.56097483, -0.06848951, -0.45193845],\n",
       "        [ 0.82737724,  1.35557354, -0.53489116, -0.40101668,  0.58595414,\n",
       "          0.67929458, -0.06848951, -0.45193845]]))"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "\n",
    "# Define features (X) and target (y)\n",
    "\n",
    "X_train = data_final.drop('Survived', axis=1)\n",
    "\n",
    "y_train = data_final['Survived']\n",
    "\n",
    "\n",
    "X_test = test_data_final\n",
    "\n",
    "# Scale numerical features\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "\n",
    "\n",
    "X_train_scaled[:5], X_test_scaled[:5]  # Display a few scaled samples for verification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['PassengerId'] not in index\"",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[55], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m X_test \u001b[38;5;241m=\u001b[39m \u001b[43mtest_data_final\u001b[49m\u001b[43m[\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mPassengerId\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mPclass\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSex\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mAge\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mFare\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mEmbarked\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mFamilySize\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\OMEN\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\frame.py:4108\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   4106\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n\u001b[0;32m   4107\u001b[0m         key \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(key)\n\u001b[1;32m-> 4108\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_indexer_strict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcolumns\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m   4110\u001b[0m \u001b[38;5;66;03m# take() does not accept boolean indexers\u001b[39;00m\n\u001b[0;32m   4111\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(indexer, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\OMEN\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexes\\base.py:6200\u001b[0m, in \u001b[0;36mIndex._get_indexer_strict\u001b[1;34m(self, key, axis_name)\u001b[0m\n\u001b[0;32m   6197\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   6198\u001b[0m     keyarr, indexer, new_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_non_unique(keyarr)\n\u001b[1;32m-> 6200\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_raise_if_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkeyarr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindexer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   6202\u001b[0m keyarr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtake(indexer)\n\u001b[0;32m   6203\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(key, Index):\n\u001b[0;32m   6204\u001b[0m     \u001b[38;5;66;03m# GH 42790 - Preserve name from an Index\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\OMEN\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\pandas\\core\\indexes\\base.py:6252\u001b[0m, in \u001b[0;36mIndex._raise_if_missing\u001b[1;34m(self, key, indexer, axis_name)\u001b[0m\n\u001b[0;32m   6249\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNone of [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkey\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m] are in the [\u001b[39m\u001b[38;5;132;01m{\u001b[39;00maxis_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m]\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   6251\u001b[0m not_found \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(ensure_index(key)[missing_mask\u001b[38;5;241m.\u001b[39mnonzero()[\u001b[38;5;241m0\u001b[39m]]\u001b[38;5;241m.\u001b[39munique())\n\u001b[1;32m-> 6252\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnot_found\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mKeyError\u001b[0m: \"['PassengerId'] not in index\""
     ]
    }
   ],
   "source": [
    "X_test = test_data_final[['Pclass', 'Sex', 'Age', 'Fare', 'Embarked', 'FamilySize']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "log_reg = LogisticRegression(solver='lbfgs', max_iter=1000, random_state=42)\n",
    "log_reg.fit(X_train_scaled, y_train)\n",
    "y_pred = log_reg.predict(X_test_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows in test_data_final: 418\n",
      "Rows in X_test_scaled: 418\n",
      "Length of y_pred_test: 418\n"
     ]
    }
   ],
   "source": [
    "print(\"Rows in test_data_final:\", test_data_final.shape[0])\n",
    "print(\"Rows in X_test_scaled:\", X_test_scaled.shape[0])\n",
    "print(\"Length of y_pred_test:\", len(y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data['Survived'] = y_pred\n",
    "test_data[['PassengerId', 'Survived']].to_csv(\"predictions.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
